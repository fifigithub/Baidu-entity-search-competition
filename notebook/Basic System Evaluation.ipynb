{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic System Evaluation\n",
    "\n",
    "To fully understand the task, and the difficulties, I'll run one pass of evaluation in this NB. After the initial exploration, we can productionize this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sklearn\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=None):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if k is None:\n",
    "        k = len(predicted)\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "sub_tasks = ['celebrity', 'movie', 'restaurant', 'tvShow']\n",
    "trainset_locs = ['../data/TRAIN SET/%s.TRAINSET.txt' % t for t in sub_tasks]\n",
    "devset_locs = ['../data/DEV SET/%s.DEVSET.txt' % t for t in sub_tasks]\n",
    "output_locs = ['../output/%s.txt' % t for t in sub_tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie': 1.0, 'celebrity': 1.0, 'tvShow': 1.0, 'restaurant': 1.0}\n",
      "{'movie': 0.13324746754540753, 'celebrity': 0.06995830022609754, 'tvShow': 0.07271910815350574, 'restaurant': 0.08773748221660245}\n"
     ]
    }
   ],
   "source": [
    "# loading datasets\n",
    "def LoadInData(data_loc, test_data=False):\n",
    "    lines = unicode(open(data_loc).read(), 'gbk').split('\\n')\n",
    "    parsing_result = []\n",
    "    for line in lines:\n",
    "        terms = line.split('\\t')\n",
    "        items = []\n",
    "        for i in terms[1:]:\n",
    "            if test_data:\n",
    "                ent, score = i, None\n",
    "\n",
    "            else:\n",
    "                colon_separated = i.split(':')\n",
    "                ent = ':'.join(colon_separated[:-1])\n",
    "                score = int(colon_separated[-1])\n",
    "            items.append((ent, score))\n",
    "        if len(items) == 0:\n",
    "            continue\n",
    "        parsing_result.append((terms[0], items))\n",
    "    return parsing_result\n",
    "\n",
    "\n",
    "# take celebrity as example\n",
    "cel_train_data = LoadInData(trainset_locs[0])\n",
    "\n",
    "# Basic strategies, and how to evaluate\n",
    "\n",
    "def NoReorder(q, results):\n",
    "    return results\n",
    "\n",
    "def Reversed(q, results):\n",
    "    return list(reversed(results))\n",
    "\n",
    "def EvaluateByRank(strategy, train_data=cel_train_data):\n",
    "    score_results = []\n",
    "    for query, gs_result in train_data:\n",
    "        my_result = strategy(query, [i for (i, t) in gs_result])\n",
    "        gs_result = [i for i, t in gs_result if t == 1]\n",
    "        score_results.append(apk(gs_result, my_result))\n",
    "        \n",
    "    return sum(score_results) / len(score_results)\n",
    "\n",
    "def EvaluateAllByRank(strategy):\n",
    "    result = {}\n",
    "    for sub_task, train_loc in zip(sub_tasks, trainset_locs):\n",
    "        train_data = LoadInData(train_loc)\n",
    "        result[sub_task] = EvaluateByRank(strategy, train_data)\n",
    "    return result\n",
    "\n",
    "print EvaluateAllByRank(NoReorder)\n",
    "print EvaluateAllByRank(Reversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie': 0.32330062464220133, 'celebrity': 0.32605351222452034, 'tvShow': 0.22679582987293437, 'restaurant': 0.2338259004008226}\n"
     ]
    }
   ],
   "source": [
    "def OrderByScore(func):\n",
    "    def wrappee(q, results):\n",
    "        return [r for s, r in sorted([\n",
    "                    (func(q, r), r) for r in results\n",
    "                ], reverse=True)]\n",
    "    return wrappee\n",
    "\n",
    "# Try a real metric\n",
    "@OrderByScore\n",
    "def CharOverlap(q, r):\n",
    "    return len(set(q).intersection(set(r)))\n",
    "\n",
    "print EvaluateAllByRank(CharOverlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exporting results into a file\n",
    "\n",
    "for output_filename, testdata_loc in zip(output_locs, devset_locs):\n",
    "    testdata = LoadInData(testdata_loc, test_data=True)\n",
    "    with open(output_filename, 'w') as ofile:\n",
    "        for query, entries in testdata:\n",
    "            my_result = CharOverlap(query, [i for (i, t) in entries])\n",
    "            print >> ofile, '\\t'.join([query] + my_result).encode('gbk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
